{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import re\n",
    "import ast\n",
    "import pickle as pkl\n",
    "\n",
    "from ahh import vis, ext\n",
    "from sklearn import linear_model\n",
    "from scipy.stats.stats import pearsonr, combine_pvalues\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "CONCEPTUAL = False\n",
    "POS_NEG = False\n",
    "SAVE = False\n",
    "RUN_ID = 99  # 11 is good jk5, straight, all; 12 is jk1, 13 is half validation period, 15 is jk3, 16 is +-ï¼Œ 99 is test\n",
    "JK_INT = 3  # jack knife (split if 0)\n",
    "# MONTHS = range(1, 13)\n",
    "MONTHS = [99]\n",
    "LEADS = range(1, 12)\n",
    "TIMESCALE = 'daily'\n",
    "\n",
    "YEARS = None  # None will be automatic\n",
    "TIME_BEHIND = 0\n",
    "LR = True\n",
    "VAR_LIST = ['sst', 'wwv']\n",
    "\n",
    "# CONSTANTS BELOW\n",
    "\n",
    "SST_FP = 'data/pkl/sst_k.pkl'\n",
    "WWV_FP = 'data/pkl/wwv_m3.pkl'\n",
    "WND_FP = 'data/pkl/wnd_ms.pkl'\n",
    "CSV_FP_FMT = 'output/{0}_{1:03d}.csv'\n",
    "POS_NEG_LIST = ['positive', 'negative']\n",
    "\n",
    "NINO34_LIM = vis.get_region_latlim('nino34', w2e=True)\n",
    "SCALER = MinMaxScaler(feature_range=(-1, 1))\n",
    "STATS = ['corr', 'pval', 'rmse']\n",
    "KEYS = ['values', 'stat', 'lead', 'month',\n",
    "        'year', 'timescale', 'var', 'lr', 'jk_int', 'time_behind']\n",
    "TS_KEYS = ['valid_y', 'valid_z'] + STATS + KEYS[2:]\n",
    "\n",
    "LSTM_H5_SAVE_FMT = 'models/{lead}_{month}_{year}_{timescale}_{var}_{lr}_{jk_int}_{time_behind}.h5'\n",
    "LSTM_JSON_SAVE_FMT = 'models/{lead}_{month}_{year}_{timescale}_{var}_{lr}_{jk_int}_{time_behind}.json'\n",
    "LR_SAVE_FMT = 'models/{lead}_{month}_{year}_{timescale}_{var}_{lr}_{jk_int}_{time_behind}.pkl'\n",
    "OFFSET_SCALE_SAVE_FMT = 'models/{lead}_{month}_{year}_{timescale}_{var}_{lr}_{jk_int}_{time_behind}.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timescale_settings(timescale):\n",
    "    if timescale == 'monthly':\n",
    "        daily = False\n",
    "        time_multiplier = 1\n",
    "    else:\n",
    "        daily = True\n",
    "        time_multiplier = 31\n",
    "    return daily, time_multiplier\n",
    "\n",
    "\n",
    "def convert_resolution(df, daily=True):\n",
    "    var_name = df.columns[0]\n",
    "    if daily:\n",
    "        gb_df = df.groupby([df.index.year, df.index.month])\n",
    "        gb_df_list = []\n",
    "        for i, group in enumerate(sorted(gb_df.groups)):\n",
    "            group_df = gb_df.get_group(group)\n",
    "            column = [datetime.datetime(group[0], group[1], 1)]\n",
    "            group_df = group_df.reset_index().drop('time', axis=1)\n",
    "            group_df.columns = column\n",
    "            group_df = group_df.reindex(range(1, 32), method='ffill')\n",
    "            gb_df_list.append(group_df)\n",
    "        converted_df = pd.concat(gb_df_list, axis=1).T\n",
    "        converted_df.columns = ['{0}_day{1:02d}'.format(var_name, col) for col in converted_df.columns]\n",
    "        del gb_df_list\n",
    "    else:\n",
    "        converted_df = df.resample('1MS').mean()  # monthly\n",
    "    return converted_df\n",
    "\n",
    "\n",
    "def shift_by_lead_lag(df, lead, lag):\n",
    "    col_len = len(df.columns)\n",
    "    for col in df.columns:\n",
    "        for alag in range(lag + 1):\n",
    "            df['lag{0:02d}_lead{1:02d}_{2}'.format(alag, lead, col)] = df[col].shift(lead + alag)\n",
    "    df = df[df.columns[col_len:]]\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def sort_df_cols(df, var_name, daily=True):\n",
    "    if daily:\n",
    "        sorted_cols = ['lag{0:02d}_lead{1:02d}_{2}_day{3:02d}'.format(alag,\n",
    "                                                                      lead,\n",
    "                                                                      var_name,\n",
    "                                                                      day) \n",
    "                           for alag in range(TIME_BEHIND, -1, -1)\n",
    "                               for day in range(1, 32)]\n",
    "        df = df[sorted_cols]\n",
    "    else:\n",
    "        df = df[df.columns[::-1]]\n",
    "    return df\n",
    "\n",
    "\n",
    "def scale_df(df):\n",
    "    df_indx = df.index\n",
    "    df_cols = df.columns\n",
    "    scaled_df = pd.DataFrame(SCALER.fit_transform(df),\n",
    "                             columns=df_cols,\n",
    "                             index=df_indx)\n",
    "    offset = SCALER.min_\n",
    "    scale = SCALER.scale_\n",
    "    return scaled_df, offset, scale\n",
    "\n",
    "\n",
    "def divide_train_val(df):\n",
    "    if JK_INT != 0:\n",
    "        train = df.loc[~((df.index.year > year - JK_INT) & (df.index.year <= year))]\n",
    "        valid = df.loc[((df.index.year > year - JK_INT) & (df.index.year <= year))]\n",
    "    else:\n",
    "        mid_date = '2000-04-01'\n",
    "        train = df.loc[df.index < mid_date]\n",
    "        valid = df.iloc[df.index >= mid_date]\n",
    "    \n",
    "    if CONCEPTUAL:\n",
    "        print(train['sst'])\n",
    "        print(valid['sst'])\n",
    "    \n",
    "    valid_idx = valid.index\n",
    "    train = train.values\n",
    "    valid = valid.values\n",
    "\n",
    "    train_x, train_y = train[:, 1:], train[:, 0]\n",
    "    valid_x, valid_y = valid[:, 1:], valid[:, 0]  # predictors, obs\n",
    "    return train_x, train_y, valid_x, valid_y, valid_idx\n",
    "\n",
    "\n",
    "def reshape_x(fcst_dict):\n",
    "    if LR:\n",
    "        fcst_dict['train_x'] = np.rollaxis(np.stack(fcst_dict['train_x']), 1).reshape(\n",
    "            np.shape(fcst_dict['train_x'])[1], time_multiplier * (TIME_BEHIND + 1) * len(var_df_list))\n",
    "        fcst_dict['valid_x'] = np.rollaxis(np.stack(fcst_dict['valid_x']), 1).reshape(\n",
    "            np.shape(fcst_dict['valid_x'])[1], time_multiplier * (TIME_BEHIND + 1) * len(var_df_list))\n",
    "    else:\n",
    "        fcst_dict['train_x'] = np.rollaxis(np.stack(fcst_dict['train_x']).T, 1).reshape(\n",
    "            np.shape(fcst_dict['train_x'])[1], time_multiplier * (TIME_BEHIND + 1), len(var_df_list))\n",
    "        fcst_dict['valid_x'] = np.rollaxis(np.stack(fcst_dict['valid_x']).T, 1).reshape(\n",
    "            np.shape(fcst_dict['valid_x'])[1], time_multiplier * (TIME_BEHIND + 1), len(var_df_list))\n",
    "\n",
    "    return fcst_dict\n",
    "\n",
    "\n",
    "def train_regr(train_mod, train_obs):\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(train_mod, train_obs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lstm(train_mod, train_obs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(input_shape=(train_mod.shape[1],\n",
    "                                train_mod.shape[2]),\n",
    "                   return_sequences=True, units=50)\n",
    "             )\n",
    "    model.add(LSTM(150, return_sequences=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    model.fit(train_mod, train_obs, epochs=8,\n",
    "              batch_size=8, verbose=0, shuffle=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def unscale_df(df, offset, scale):\n",
    "    return (df - offset[0]) / scale[0]\n",
    "\n",
    "\n",
    "def get_prediction(fcst_dict, time_multiplier, offset, scale,\n",
    "                   lead, month, year):\n",
    "    train_x = fcst_dict['train_x']\n",
    "    train_y = fcst_dict['train_y']\n",
    "\n",
    "    valid_x = fcst_dict['valid_x']\n",
    "    valid_y = fcst_dict['valid_y']\n",
    "\n",
    "    if LR:\n",
    "        model = train_regr(train_x, train_y)\n",
    "    else:\n",
    "        model = train_lstm(train_x, train_y)\n",
    "\n",
    "    valid_z = model.predict(valid_x)\n",
    "    valid_z = unscale_df(valid_z, offset, scale)\n",
    "\n",
    "    valid_y = unscale_df(valid_y, offset, scale)\n",
    "\n",
    "    if not LR:\n",
    "        valid_z = valid_z[:, -1]\n",
    "    \n",
    "    if SAVE:\n",
    "        save_dict = dict(lead=lead, month=month,\n",
    "                         year=year, timescale=TIMESCALE,\n",
    "                         var='_'.join(VAR_LIST),\n",
    "                         lr=LR, jk_int=JK_INT,\n",
    "                         time_behind=TIME_BEHIND)\n",
    "        if not LR:\n",
    "            lstm_h5_save = LSTM_H5_SAVE_FMT.format(**save_dict)\n",
    "            model.save_weights(lstm_h5_save)\n",
    "\n",
    "            lstm_json_save = LSTM_JSON_SAVE_FMT.format(**save_dict)\n",
    "            lstm_json = model.to_json()\n",
    "            with open(lstm_json_save, 'w') as json_file:\n",
    "                json_file.write(lstm_json)\n",
    "                \n",
    "        else:\n",
    "            lr_save = LR_SAVE_FMT.format(**save_dict)\n",
    "            with open(lr_save, 'wb') as fi:\n",
    "                pkl.dump(model, fi)\n",
    "\n",
    "    return valid_y, valid_z\n",
    "\n",
    "\n",
    "def get_corr_pval_rmse(arr1, arr2):\n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "    corr_pval = pearsonr(arr1, arr2)\n",
    "    rmse = np.sqrt(mse(arr1, arr2))\n",
    "    return corr_pval[0], corr_pval[1], rmse\n",
    "\n",
    "\n",
    "def write_stat(val, stat, lead, month, year):\n",
    "    fn = CSV_FP_FMT.format(stat, RUN_ID)\n",
    "    write_dict = dict(val=val, stat=stat,\n",
    "                      lead=lead, month=month,\n",
    "                      year=year, timescale=TIMESCALE,\n",
    "                      var='_'.join(VAR_LIST), lr=LR, jk_int=JK_INT,\n",
    "                      time_behind=TIME_BEHIND)\n",
    "    with open(fn, 'a') as file:\n",
    "        file.write('{val}, {stat}, {lead}, {month}, {year}, {timescale}, {var}, {lr}, {jk_int}, {time_behind}\\n'.format(**write_dict))\n",
    "    return fn\n",
    "\n",
    "\n",
    "def write_timeseries(df_ts_out):\n",
    "    df_ts_out = df_ts_out[TS_KEYS]\n",
    "    fn = CSV_FP_FMT.format('time', RUN_ID)\n",
    "    with open(fn, 'a') as f:\n",
    "        df_ts_out.to_csv(f, header=False)\n",
    "    return fn\n",
    "\n",
    "\n",
    "def get_label(month):\n",
    "    label = 'jk{jk_int}_{month}_{time_behind}_{timescale}_{lr}_with_{var}'.format(\n",
    "        lr='lr' if LR else 'lstm',\n",
    "        month='segmented' if month != 99 else 'linked',\n",
    "        time_behind=TIME_BEHIND,\n",
    "        timescale=TIMESCALE,\n",
    "        var='_'.join(VAR_LIST),\n",
    "        jk_int=JK_INT,\n",
    "    ).replace(' ', '')\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_cleansed_df(fn, time=False):\n",
    "    if not time:\n",
    "        df = pd.read_csv(fn, header=None, names=KEYS)\n",
    "    else:\n",
    "        df = pd.read_csv(fn, header=None, names=TS_KEYS)\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    if not time:\n",
    "        df.index = range(0, len(df))\n",
    "        df['stat'] = df['stat'].str.strip()\n",
    "        df['timescale'] = df['timescale'].str.strip()\n",
    "        df['var'] = df['var'].str.strip()\n",
    "        try:\n",
    "            df['lr'] = df['lr'].str.strip().apply(ast.literal_eval)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    else:\n",
    "        fn = CSV_FP_FMT.format('time', RUN_ID)\n",
    "        df.index = pd.DatetimeIndex(df.index)\n",
    "        df.to_csv(fn, header=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_and_pivot(df, month, filter_only=False):\n",
    "    df = df.loc[(df['lr'] == LR) &\n",
    "                (df['timescale'] == TIMESCALE) &\n",
    "                (df['var'] == '_'.join(VAR_LIST)) &\n",
    "                (df['jk_int'] == JK_INT) &\n",
    "                (df['time_behind'] == TIME_BEHIND)]\n",
    "\n",
    "    if month != 99:\n",
    "        df = df.loc[df['month'] != 99].groupby(['lead', 'year']).mean().reset_index()\n",
    "    else:\n",
    "        df = df.loc[df['month'] == 99]\n",
    "\n",
    "    if not filter_only:\n",
    "        df = df.drop_duplicates(df.columns[1:])\n",
    "        df = df.pivot(index='lead', columns='year', values='values')  # pivoted\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_pivoted_csvs(corr_df, pval_df, rmse_df, month):\n",
    "    corr_df = filter_and_pivot(corr_df, month)\n",
    "    pval_df = filter_and_pivot(pval_df, month)\n",
    "    rmse_df = filter_and_pivot(rmse_df, month)\n",
    "    return corr_df, pval_df, rmse_df\n",
    "\n",
    "\n",
    "def neaten(input_str):\n",
    "    return input_str.replace('_', ' ').title()\n",
    "\n",
    "\n",
    "def get_avg_corr_pval(corr_df, pval_df, axis=None):\n",
    "    if axis is None:\n",
    "        avg_corr = np.tanh(np.arctanh(corr_df)).mean()\n",
    "        avg_pval = combine_pvalues(pval_df)[1]\n",
    "    else:\n",
    "        avg_corr = np.tanh(np.arctanh(corr_df).mean(axis=1))\n",
    "        avg_pval = list(zip(*pval_df.apply(combine_pvalues, axis=1)))[1]\n",
    "    return avg_corr, avg_pval\n",
    "\n",
    "\n",
    "def plot(corr_df, pval_df, rmse_df, label):\n",
    "    vis_dict = dict(figsize='na', xlabel='Lead', rows=2, linewidth=0.75, length_scale=False, xlim=(1, len(corr_df)))\n",
    "    _ = vis.set_figsize(12, 8)\n",
    "    clist = vis.get_color_list(vis.get_cmap('GMT_haxby', n=int(len(corr_df.columns)) + 1))\n",
    "    for i, col in enumerate(corr_df):\n",
    "        ax = vis.plot_line(corr_df.index, corr_df[col],\n",
    "                           label='{0}'.format(col),\n",
    "                           color=clist[i],\n",
    "                           ylabel='Correlation',\n",
    "                           **vis_dict)\n",
    "        ax2 = vis.plot_line(rmse_df.index, rmse_df[col],\n",
    "                            label='{0}'.format(col),\n",
    "                            color=clist[i],\n",
    "                            ylabel='RMSE',\n",
    "                            pos=2,\n",
    "                            **vis_dict)\n",
    "        i += 1\n",
    "\n",
    "    avg_corr_line, avg_pval_line = get_avg_corr_pval(corr_df, pval_df, axis=1)\n",
    "    avg_rmse_line = rmse_df.mean(axis=1)\n",
    "\n",
    "    ax = vis.plot_line(pval_df.index, avg_pval_line, label='PVal',\n",
    "                       color='gray',\n",
    "                       linestyle='--',\n",
    "                       marker='x',\n",
    "                       **vis_dict)\n",
    "\n",
    "    ax = vis.plot_line(corr_df.index, avg_corr_line, label='Mean',\n",
    "                       color='k',\n",
    "                       marker='.',\n",
    "                       ylim=(-0, 1),\n",
    "                       ylabel='Correlation',\n",
    "                       title=neaten(label),\n",
    "                       **vis_dict)\n",
    "\n",
    "    ax2 = vis.plot_line(rmse_df.index, avg_rmse_line, label='Mean'.format(i=year),\n",
    "                        color='k',\n",
    "                        marker='.',\n",
    "                        ylim=(0, 2),\n",
    "                        ylabel='RMSE',\n",
    "                        pos=2,\n",
    "                        **vis_dict)\n",
    "\n",
    "    avg_corr, avg_pval = get_avg_corr_pval(avg_corr_line, avg_pval_line)\n",
    "    vis.set_axtext(ax, 'Avg Corr All Leads: {0:.1%}'.format(avg_corr), loc='bottom right')\n",
    "    vis.set_axtext(ax2, 'Avg RMSE All Leads: {0:.3}'.format(avg_rmse_line.mean()), loc='bottom right')\n",
    "\n",
    "    ax = vis.set_legend(ax, ncol=3, size=5, loc='top right')\n",
    "    ax2 = vis.set_legend(ax2, ncol=3, size=5, loc='top right')\n",
    "\n",
    "    vis.savefig('output/{0}.png'.format(label))\n",
    "\n",
    "\n",
    "def get_row_label(df, i):\n",
    "    label = 'lead{lead}_{month}_{timescale}_tb{time_behind}_{lr}_jk{jk_int}_with_{var}'.format(\n",
    "        lr='lr' if df['lr'][i] else 'lstm',\n",
    "        month='segmented' if df['month'][i] != 99 else 'linked',\n",
    "        timescale=df['timescale'][i],\n",
    "        var=df['var'][i],\n",
    "        jk_int=df['jk_int'][i],\n",
    "        lead=df['lead'][i],\n",
    "        time_behind=df['time_behind'][i]\n",
    "    ).replace(' ', '')\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_summary(df):\n",
    "    summary_list = []\n",
    "    for i in range(len(df)):\n",
    "        summary_list.append(get_row_label(df, i))\n",
    "    summary_unique = np.unique(summary_list)\n",
    "    del summary_list\n",
    "    summary_len = len(summary_unique)\n",
    "    max_leads = int(summary_unique[-1][4])\n",
    "    return summary_unique[int(-summary_len / max_leads):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.datetime.utcnow()\n",
    "\n",
    "if CONCEPTUAL:\n",
    "    dt_range = pd.date_range('1982-01-01', '2017-12-31')\n",
    "    sst_df = pd.DataFrame({'sst': dt_range.month}, index=dt_range)\n",
    "    sst_df.index.name = 'time'\n",
    "\n",
    "    wwv_df = pd.DataFrame({'wwv': dt_range.month * 10}, index=dt_range)\n",
    "    wwv_df.index.name = 'time'\n",
    "\n",
    "    wnd_df = pd.DataFrame({'wnd': dt_range.month * 10}, index=dt_range)\n",
    "    wnd_df.index.name = 'time'\n",
    "else:\n",
    "    sst_df = pd.read_pickle(SST_FP)\n",
    "    wwv_df = pd.read_pickle(WWV_FP)\n",
    "    wnd_df = pd.read_pickle(WND_FP)\n",
    "\n",
    "if YEARS is None and JK_INT != 0:\n",
    "    years = np.unique(sst_df.index.year)[JK_INT::JK_INT]\n",
    "elif JK_INT == 0:\n",
    "    years = np.unique(sst_df.index.year)\n",
    "else:\n",
    "    years = YEARS\n",
    "\n",
    "obs_col = sst_df['sst'].resample('1MS').mean()\n",
    "\n",
    "var_df_list = []\n",
    "for var in VAR_LIST:\n",
    "    if var == 'sst':\n",
    "        var_df_list.append(('sst', sst_df))\n",
    "    elif var == 'wwv':\n",
    "        var_df_list.append(('wwv', wwv_df))\n",
    "    elif var == 'wnd':\n",
    "        var_df_list.append(('wnd', wnd_df))\n",
    "\n",
    "df_list = []\n",
    "for year in years:\n",
    "    for i, lead in enumerate(LEADS):\n",
    "        print('\\n{0} | {1} Lead: {2}'.format(datetime.datetime.utcnow() - s, year, lead), end=\" - \")\n",
    "        for month in MONTHS:\n",
    "            print(month, end= \" \")\n",
    "            daily, time_multiplier = get_timescale_settings(TIMESCALE)\n",
    "\n",
    "            fcst_pos_neg_dict = {}  # used if POS_NEG == True\n",
    "            pos_neg_loc_dict = {}\n",
    "            for j, pos_neg in enumerate(POS_NEG_LIST):  # if POS_NEG\n",
    "                fcst_dict = {'train_x': [], 'valid_x': []}\n",
    "                for i, (var_name, var_df) in enumerate(var_df_list):\n",
    "                    shifted_df = shift_by_lead_lag(convert_resolution(var_df, daily), lead, TIME_BEHIND)\n",
    "                    sorted_df = sort_df_cols(shifted_df, var_name, daily=daily)\n",
    "                    entire_fcst_df = pd.concat([obs_col, sorted_df], axis=1).dropna()\n",
    "\n",
    "                    if POS_NEG:\n",
    "                        if 'sst' in VAR_LIST:\n",
    "                            pos_neg_var = 'sst'\n",
    "                        elif 'wwv' in VAR_LIST:\n",
    "                            pos_neg_var = 'wwv'\n",
    "                        else:\n",
    "                            pos_neg_var = 'wnd'\n",
    "                    \n",
    "                        if i == 0:\n",
    "                            if TIMESCALE == 'daily':\n",
    "                                col_fmt = 'lag00_lead{0:02d}_{1}_day01'\n",
    "                            elif TIMESCALE == 'monthly':\n",
    "                                col_fmt = 'lag00_lead{0:02d}_{1}'\n",
    "\n",
    "                            pos_neg_loc_dict['positive'] = entire_fcst_df[col_fmt.format(lead, pos_neg_var)] >= 0\n",
    "                            pos_neg_loc_dict['negative'] = entire_fcst_df[col_fmt.format(lead, pos_neg_var)] < 0\n",
    "\n",
    "                        fcst_df = entire_fcst_df.loc[pos_neg_loc_dict[pos_neg]]\n",
    "                    else:\n",
    "                        fcst_df = entire_fcst_df\n",
    "                        \n",
    "                    if month != 99:\n",
    "                        fcst_df = fcst_df.loc[fcst_df.index.month == month]\n",
    "\n",
    "                    scaled_df, offset, scale = scale_df(fcst_df)\n",
    "\n",
    "                    if SAVE:\n",
    "                        save_dict = dict(lead=lead, month=month,\n",
    "                             year=year, timescale=TIMESCALE,\n",
    "                             var=var_name, lr=LR, jk_int=JK_INT,\n",
    "                             time_behind=TIME_BEHIND)\n",
    "\n",
    "                        offset_scale = np.array([offset, scale])\n",
    "                        offset_scale_save = OFFSET_SCALE_SAVE_FMT.format(**save_dict)\n",
    "                        pkl_save = np.save(offset_scale_save, offset_scale)\n",
    "\n",
    "                    if CONCEPTUAL:\n",
    "                        train_x, train_y, valid_x, valid_y, valid_idx = divide_train_val(fcst_df)\n",
    "                    else:\n",
    "                        train_x, train_y, valid_x, valid_y, valid_idx = divide_train_val(scaled_df)\n",
    "\n",
    "                    fcst_dict['train_x'].append(train_x.reshape(len(train_x), time_multiplier * (TIME_BEHIND + 1)))\n",
    "                    fcst_dict['valid_x'].append(valid_x.reshape(len(valid_x), time_multiplier * (TIME_BEHIND + 1)))\n",
    "                    if i == 0:\n",
    "                        fcst_dict['train_y'] = train_y\n",
    "                        fcst_dict['valid_y'] = valid_y\n",
    "                        fcst_dict['valid_idx'] = valid_idx\n",
    "\n",
    "                if POS_NEG:\n",
    "                    fcst_pos_neg_dict[pos_neg] = fcst_dict\n",
    "\n",
    "                elif not POS_NEG:\n",
    "                    break\n",
    "\n",
    "            pos_neg_df_list = []\n",
    "            for j, pos_neg in enumerate(POS_NEG_LIST):\n",
    "                if POS_NEG:\n",
    "                    fcst_dict = fcst_pos_neg_dict[pos_neg]\n",
    "\n",
    "                fcst_dict = reshape_x(fcst_dict)\n",
    "                valid_y, valid_z = get_prediction(fcst_dict, time_multiplier, offset, scale, lead, month, year)\n",
    "                if POS_NEG:\n",
    "                    pos_neg_df_list.append(pd.DataFrame(data={'valid_y': valid_y, 'valid_z': valid_z},\n",
    "                                                        index=fcst_dict['valid_idx']))\n",
    "                    if j == 1:\n",
    "                        pos_neg_df = pd.concat(pos_neg_df_list)\n",
    "                        valid_y = pos_neg_df['valid_y']\n",
    "                        valid_z = pos_neg_df['valid_z']\n",
    "                elif not POS_NEG:\n",
    "                    break\n",
    "\n",
    "            corr, pval, rmse = get_corr_pval_rmse(valid_y, valid_z)\n",
    "\n",
    "            if not CONCEPTUAL:\n",
    "                corr_fn = write_stat(corr, 'corr', lead, month, year)\n",
    "                pval_fn = write_stat(pval, 'pval', lead, month, year)\n",
    "                rmse_fn = write_stat(rmse, 'rmse', lead, month, year)\n",
    "\n",
    "                df_ts_dict = dict(valid_y=valid_y, valid_z=valid_z,\n",
    "                                  corr=corr, pval=pval, rmse=rmse,\n",
    "                                  lead=lead, month=month,\n",
    "                                  year=year, timescale=TIMESCALE,\n",
    "                                  var='_'.join(VAR_LIST),\n",
    "                                  lr=LR, jk_int=JK_INT,\n",
    "                                  time_behind=TIME_BEHIND)\n",
    "                df_ts_out = pd.DataFrame(df_ts_dict, index=valid_idx)\n",
    "\n",
    "                time_fn = write_timeseries(df_ts_out)\n",
    "            \n",
    "            if month == 99:\n",
    "                break\n",
    "        if CONCEPTUAL:\n",
    "            break\n",
    "\n",
    "    if CONCEPTUAL or JK_INT == 0:\n",
    "        break\n",
    "\n",
    "del var_df_list\n",
    "print('\\nDONE!')\n",
    "\n",
    "if not CONCEPTUAL:\n",
    "    corr_fn = CSV_FP_FMT.format('corr', RUN_ID)\n",
    "    pval_fn = CSV_FP_FMT.format('pval', RUN_ID)\n",
    "    rmse_fn = CSV_FP_FMT.format('rmse', RUN_ID)\n",
    "    time_fn = CSV_FP_FMT.format('time', RUN_ID)\n",
    "\n",
    "    label = get_label(month)\n",
    "    corr_df = get_cleansed_df(corr_fn)\n",
    "    pval_df = get_cleansed_df(pval_fn)\n",
    "    rmse_df = get_cleansed_df(rmse_fn)\n",
    "    time_df = get_cleansed_df(time_fn, time=True)\n",
    "    time_df = filter_and_pivot(time_df, month, filter_only=True)\n",
    "    get_summary(corr_df)\n",
    "\n",
    "    corr_df, pval_df, rmse_df = get_pivoted_csvs(corr_df, pval_df, rmse_df, month)\n",
    "    plot(corr_df, pval_df, rmse_df, label)  # add print correlation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
